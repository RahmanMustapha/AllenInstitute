#Imports
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
%matplotlib inline
import os
import scipy.stats as st

#pd.set_option("display.max_rows", None, "display.max_columns", None)
pd.reset_option('all')

from allensdk.core.brain_observatory_cache import BrainObservatoryCache
import pprint
import allensdk.brain_observatory.stimulus_info as stim_info
from allensdk.brain_observatory.drifting_gratings import DriftingGratings



boc = BrainObservatoryCache()

exp_test = boc.get_ophys_experiments(cre_lines=['Vip-IRES-Cre'], stimuli=['drifting_gratings'], 
                                     targeted_structures=['VISp'])
print("Experiments for test: %d\n" % (len(exp_test)))

# Download experiment containers for VISp experiments
visal_ecs = boc.get_experiment_containers(targeted_structures=['VISal'])
print("all VISal experiment containers: %d" % len(visal_ecs))

# Download experiment containers for VISp experiments
visam_ecs = boc.get_experiment_containers(targeted_structures=['VISam'])
print("all VISam experiment containers: %d" % len(visam_ecs))

# Download experiment containers for VISp experiments
visl_ecs = boc.get_experiment_containers(targeted_structures=['VISl'])
print("all VISl experiment containers: %d" % len(visl_ecs))

# Download experiment containers for VISp experiments
visp_ecs = boc.get_experiment_containers(targeted_structures=['VISp'])
print("all VISp experiment containers: %d" % len(visp_ecs))

# Download experiment containers for VISp experiments
vispm_ecs = boc.get_experiment_containers(targeted_structures=['VISpm'])
print("all VISpm experiment containers: %d" % len(vispm_ecs))

# Download experiment containers for VISp experiments
visrl_ecs = boc.get_experiment_containers(targeted_structures=['VISrl'])
print("all VISrl experiment containers: %d" % len(visrl_ecs))


#Example session download for testing purposes 
session_id0 = exp_test[0]['id']
print(session_id0)

data_set0 = boc.get_ophys_experiment_data(session_id0)
pprint.pprint(data_set0.get_metadata())

#Stimulus Table
drifting_gratings_table0 = data_set0.get_stimulus_table("drifting_gratings")
drifting_gratings_table0



#function to get lower and upper limit of values in null distribution bootstrap
def null_distribution_bootstrap(num_shuffles, cell_responses, total_neurons, avg): 
    shuffle_dist =  np.zeros(num_shuffles)
    for i_shuffle in range(num_shuffles):
        shuffle_dist[i_shuffle] = np.mean(cell_responses[np.random.choice(total_neurons,size=(total_neurons,))])
        
    low_lim = [np.percentile(shuffle_dist, 2.5)] #- np.array([avg])
    up_lim = [np.percentile(shuffle_dist, 97.5)] #- np.array([avg])
    lims = np.ndarray.flatten(np.absolute(np.vstack((low_lim, up_lim))))
       
    return lims



def get_unique_orientations(dg_table):

    pre_ORIs = dg_table['orientation'].unique() 
    ORIs = [x for x in pre_ORIs if np.isnan(x) == False]
    return ORIs

def get_unique_temporal_frequencies(dg_table):

    pre_TFs = dg_table['temporal_frequency'].unique()
    TFs = [x for x in pre_TFs if np.isnan(x) == False]
    return TFs

def get_condition_trials(dg_table, ori, tf):
    trials_in_condition = (dg_table['orientation'] == ori) & (dg_table['temporal_frequency'] == tf)
        
    condition_trial_indices = np.argwhere(trials_in_condition)
     
    just_indices = []
    for sublist in condition_trial_indices:
        just_indices.append(sublist[0])
        
    return just_indices

def get_blank_trials(dg_table):
    for ori_idx, current_ori in enumerate(get_unique_orientations(dg_table)):
        for TF_idx, current_tf in enumerate(get_unique_temporal_frequencies(dg_table)):
            trials_in_condition = (np.isnan(dg_table['orientation'])) & (np.isnan(dg_table['temporal_frequency']))
        
    condition_trial_indices = np.argwhere(trials_in_condition)
     
    just_indices = []
    for sublist in condition_trial_indices:
        just_indices.append(sublist[0])
        
    return just_indices

def get_condition_mean(dg_table,ORIs,TFs,i,j,neuron_number,dg_mean_sweeps):
    return np.nanmean(dg_mean_sweeps.iloc[get_condition_trials(dg_table, ORIs[i], TFs[j]),neuron_number])

def get_blank_mean(dg_table, neuron_number,dg_mean_sweeps):
    return np.mean(dg_mean_sweeps.iloc[get_blank_trials(dg_table),neuron_number])

#returns response matrix for a given neuron for all tf and ori conditions given its dg table and above helper functions
def get_response_matrix(dg_table, current_neuron, dg_mean_sweep_responses, threshold):
    sorted_dg_table = dg_table.sort_values(by=['temporal_frequency','orientation'])
    all_unique_orientations = get_unique_orientations(sorted_dg_table)
    all_unique_temporal_frequencies = get_unique_temporal_frequencies(sorted_dg_table)
    

    matrix = np.zeros(len(all_unique_temporal_frequencies))
    
    for i in range(len(all_unique_orientations)):
        for j in range(len(all_unique_temporal_frequencies)):
            cur_condition_response = get_condition_mean(dg_table,all_unique_orientations,all_unique_temporal_frequencies,i,j,current_neuron,dg_mean_sweep_responses)
            if cur_condition_response <= threshold:
                matrix[j] = matrix[j] + 1
                
    return matrix

#used to get upper and lower lim for error bar plots
def bootstrap(num_shuffles, cell_responses, total_neurons, ori_idx, avg): 
    shuffle_dist =  np.zeros(num_shuffles)
    for i_shuffle in range(num_shuffles):
        shuffle_dist[i_shuffle] = np.mean(cell_responses[ori_idx][np.random.choice(total_neurons,size=(total_neurons,))])
        
    low_lim = [np.percentile(shuffle_dist, 5)] - np.array([avg])
    up_lim = [np.percentile(shuffle_dist, 95)] - np.array([avg])
       
    return np.ndarray.flatten(np.absolute(np.vstack((low_lim, up_lim))))

#Dan's chi square function to perform statistical p-test
def chisq_from_stim_table(stim_table,
                          columns,
                          mean_sweep_events,
                          num_shuffles=1000,
                          verbose=False):
    #  stim_table is a pandas DataFrame with len = num_sweeps
    #  columns is a list of column names that define the categories (e.g. ['Ori','Contrast'])
    #  mean_sweep_events is a numpy array with shape (num_sweeps,num_cells)
    
    sweep_categories = stim_table_to_categories(stim_table,columns,verbose=verbose)
    p_vals = compute_chi_shuffle(mean_sweep_events,sweep_categories,num_shuffles=num_shuffles)
    
    return p_vals

def compute_chi_shuffle(mean_sweep_events,
                        sweep_categories,
                        num_shuffles=1000):

    #  mean_sweep_events is a numpy array with shape (num_sweeps,num_cells)
    #  sweep_conditions is a numpy array with shape (num_sweeps)
    #       sweep_conditions gives the category label for each sweep
    
    (num_sweeps,num_cells) = np.shape(mean_sweep_events) 
    
    assert len(sweep_categories) == num_sweeps
    
    sweep_categories_dummy = make_category_dummy(sweep_categories)
    
    expected = compute_expected(mean_sweep_events,sweep_categories_dummy)
    observed = compute_observed(mean_sweep_events,sweep_categories_dummy)
    chi_actual = compute_chi(observed,expected)
    
    chi_shuffle = np.zeros((num_cells,num_shuffles))
    for ns in range(num_shuffles):
        #print 'shuffle ' + str(ns+1) + ' of ' + str(num_shuffles)
        
        shuffle_sweeps = np.random.choice(num_sweeps,size=(num_sweeps,))
        shuffle_sweep_events = mean_sweep_events[shuffle_sweeps]
        
        shuffle_expected = compute_expected(shuffle_sweep_events,sweep_categories_dummy)
        shuffle_observed = compute_observed(shuffle_sweep_events,sweep_categories_dummy)
        
        chi_shuffle[:,ns] = compute_chi(shuffle_observed,shuffle_expected)
    
    p_vals = np.mean(chi_actual.reshape(num_cells,1)<chi_shuffle,axis=1)
    
    return p_vals

def stim_table_to_categories(stim_table,
                             columns,
                             verbose=False):
    # get the categories for all sweeps with each unique combination of 
    #   parameters in 'columns' being one category
    # sweeps with non-finite values in ANY column (e.g. np.NaN) are labeled 
    #   as blank sweeps (category = -1)
    
    num_sweeps = len(stim_table)
    num_params = len(columns)
    
    unique_params = []
    options_per_column = []
    max_combination = 1
    for column in columns:
        column_params = np.unique(stim_table[column].values)
        column_params = column_params[np.isfinite(column_params)]
        unique_params.append(column_params)
        options_per_column.append(len(column_params))
        max_combination*=len(column_params)

    category = 0
    sweep_categories = -1*np.ones((num_sweeps,))
    curr_combination = np.zeros((num_params,),dtype=np.int)
    options_per_column = np.array(options_per_column).astype(np.int)
    all_tried = False
    while not all_tried:
        
        matches_combination = np.ones((num_sweeps,),dtype=np.bool)
        for i_col,column in enumerate(columns):
            param = unique_params[i_col][curr_combination[i_col]]
            matches_param = stim_table[column].values == param
            matches_combination *= matches_param
            
        if np.any(matches_combination):
            sweep_categories[matches_combination] = category
            if verbose:
                print ('Category ' + str(category))
                for i_col,column in enumerate(columns):
                    param = unique_params[i_col][curr_combination[i_col]]
                    print (column + ': ' + str(param))
            
            category+=1
              
        #advance the combination
        curr_combination = advance_combination(curr_combination,options_per_column)
        all_tried = curr_combination[0]==options_per_column[0]
    
    if verbose:    
        blank_sweeps = sweep_categories==-1
        print ('num blank: ' + str(blank_sweeps.sum()))
        
    return sweep_categories
    
def advance_combination(curr_combination,
                        options_per_column):
    
    num_cols = len(curr_combination)
    
    might_carry = True
    col = num_cols-1
    while might_carry:
        curr_combination[col] += 1
        if col==0 or curr_combination[col]<options_per_column[col]:
            might_carry = False
        else:
            curr_combination[col] = 0
            col-=1
            
    return curr_combination
    

def make_category_dummy(sweep_categories):
    #makes a dummy variable version of the sweep category list
    
    num_sweeps = len(sweep_categories)
    categories = np.unique(sweep_categories)
    num_categories = len(categories)
    
    sweep_category_mat = np.zeros((num_sweeps,num_categories),dtype=np.bool)
    for i_cat,category in enumerate(categories):
        category_idx = np.argwhere(sweep_categories==category)[:,0]
        sweep_category_mat[category_idx,i_cat] = True
    
    return sweep_category_mat

def compute_observed(mean_sweep_events,sweep_conditions):

    (num_sweeps,num_conditions) = np.shape(sweep_conditions)
    num_cells = np.shape(mean_sweep_events)[1]   
    
    observed_mat = (mean_sweep_events.T).reshape(num_cells,num_sweeps,1) * sweep_conditions.reshape(1,num_sweeps,num_conditions)
    observed = np.sum(observed_mat,axis=1)
    
    return observed
    
def compute_expected(mean_sweep_events,sweep_conditions):   
    
    num_conditions = np.shape(sweep_conditions)[1]
    num_cells = np.shape(mean_sweep_events)[1]
    
    sweeps_per_condition = np.sum(sweep_conditions,axis=0)
    events_per_sweep = np.mean(mean_sweep_events,axis=0)
    
    expected = sweeps_per_condition.reshape(1,num_conditions) * events_per_sweep.reshape(num_cells,1) 
    
    return expected

def compute_chi(observed,expected):

    chi = (observed - expected) ** 2 /expected
    chi = np.where(expected>0,chi,0.0)  
    return np.sum(chi,axis=1)


#gets all neuron responses within a given creline and puts them ina matrix
def get_all_experiment_neurons(cre):
    
    og_arr  = np.empty((0, (len(dg0.tfvals) - 1)), int)
    TF_SbC_tuning = np.array(og_arr).T   
    cell_exp = boc.get_ophys_experiments(cre_lines=[cre], stimuli=[stim_info.DRIFTING_GRATINGS])
    
    for i_exp in cell_exp:

        data_set = boc.get_ophys_experiment_data(i_exp['id'])
        dg = DriftingGratings(data_set)
        dg_peak = dg.peak

        dg_tbl = data_set.get_stimulus_table("drifting_gratings")
        dg_columns = list(dg_tbl.columns[0:2])
        dg_mean_sweep_events = dg.mean_sweep_response.iloc[:,:-1]
        total_neurons = dg_mean_sweep_events.shape[1]
        threshold = 0
        all_cell_responses =  np.zeros(((len(dg.tfvals) - 1), total_neurons))

        for cur_neuron in range(total_neurons):
            #Get Response Matrix
            response_matrix = get_response_matrix(dg_tbl, cur_neuron, dg_mean_sweep_events, threshold)        
            all_cell_responses[:,cur_neuron] = response_matrix

        TF_SbC_tuning = np.append(TF_SbC_tuning, all_cell_responses, axis=1)

    return TF_SbC_tuning


#gets all neurons responses within a given cre line and averages them according to experiment
def get_all_experiment_averages(cre):
    
    og_arr  = np.empty((0, (len(dg0.tfvals) - 1)), int)
    TF_SbC_tuning = np.array(og_arr).T   
    cell_exp = boc.get_ophys_experiments(cre_lines=[cre], stimuli=[stim_info.DRIFTING_GRATINGS])
    
    for i_exp in cell_exp:

        data_set = boc.get_ophys_experiment_data(i_exp['id'])
        dg = DriftingGratings(data_set)
        dg_peak = dg.peak

        dg_tbl = data_set.get_stimulus_table("drifting_gratings")
        dg_columns = list(dg_tbl.columns[0:2])
        dg_mean_sweep_events = dg.mean_sweep_response.iloc[:,:-1]
        total_neurons = dg_mean_sweep_events.shape[1]
        threshold = 0
        all_cell_responses =  np.zeros(((len(dg.tfvals) - 1), total_neurons))

        for cur_neuron in range(total_neurons):
            #Get Response Matrix
            response_matrix = get_response_matrix(dg_tbl, cur_neuron, dg_mean_sweep_events, threshold)        
            all_cell_responses[:,cur_neuron] = response_matrix
            
        all_exp_averages = np.mean(all_cell_responses, axis=1)
        TF_SbC_tuning = np.append(TF_SbC_tuning, all_exp_averages.reshape(5, 1), axis=1)

    return TF_SbC_tuning


#computes error bar plot based on cell responses or average experiment responses
def dg_tuning_curve(all_neuron_responses, cre): 
    #all_neuron_responses = get_all_experiment_neurons(exp_array)
    name = cre[:3]
    avg_cell_responses = np.zeros((len(dg0.tfvals) - 1))
    bootstraps = np.zeros((2, (len(dg0.tfvals) - 1)))
    num_shuffles = 1000
    total_neurons = all_neuron_responses.shape[1]


    for i_ori in range((len(dg0.tfvals) - 1)):
        avg_cell_responses[i_ori]=np.mean(all_neuron_responses[i_ori,:])
        bootstraps[:,i_ori] = bootstrap(num_shuffles, all_neuron_responses, total_neurons, i_ori, avg_cell_responses[i_ori])
    #it wont accept all_cell_responses[i_ori] because bootstrap function breaks when given single array, 
    #needs to take single row of 2d matrix

    fig, ax2  = plt.subplots()
    #print(str(bootstraps))
    # plot orientation selectivity
    normalized_x = np.log(dg0.tfvals[1:])
    ax2.errorbar(normalized_x, avg_cell_responses, yerr=bootstraps, ecolor='black')
    ax2.set_xlabel('Temporal Frequencies')
    ax2.set_ylabel('Negative Reponse Orientations')
    ax2.set_xticks(normalized_x)
    ax2.set_xticklabels(dg0.tfvals[1:])
    ax2.set_yticks(np.arange(len(dg0.orivals)+1))
    ax2.set_yticklabels(range(len(dg0.orivals) + 1))
    
#     ax2.set_title(name + ' Average Error Bar Plot of Negative Orientation Selective Cell Responses')
#     plt.savefig('tuning_graph_images/' + name + '_threshold_selectivity/threshold_error_bar_plot.png', transparent=True)
    
    ax2.set_title(name + ' Average Error Bar Plot of Suppressed Experiment Responses')
    plt.savefig('tuning_graph_images/' + name + '_threshold_selectivity/threshold_experiment_error_bar_plot.png', transparent=True)
   
    #plt.savefig('tuning_graph_images/experiment' + str(exp_number) + '/neuron' + str(cur_neuron) + '_tuning_graph.png', transparent=True)
    plt.show


#define cre lines
vip_cre = 'VIP-IRES-Cre'
sst_cre = 'Sst-IRES-Cre'
cux2_cre = 'Cux2-CreERT2'

#computes respective cell responose and experiment response average matrices for each creline
all_vip_cells = get_all_experiment_neurons(vip_cre)
all_vip_averages = get_all_experiment_averages(vip_cre)

all_cux2_cells = get_all_experiment_neurons(cux2_cre)
all_cux2_averages = get_all_experiment_averages(cux2_cre)

all_sst_cells = get_all_experiment_neurons(sst_cre)
all_sst_averages = get_all_experiment_averages(sst_cre)



#computes error bar plots for cell responose and experiment response average matrices for each creline
dg_tuning_curve(all_vip_cells, vip_cre)
dg_tuning_curve(all_vip_averages, vip_cre)

dg_tuning_curve(all_cux2_cells, cux2_cre)
dg_tuning_curve(all_cux2_averages, cux2_cre)

dg_tuning_curve(all_sst_cells, sst_cre)
dg_tuning_curve(all_sst_averages, sst_cre)
