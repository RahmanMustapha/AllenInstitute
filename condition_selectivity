#Imports
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
%matplotlib inline
import os
import scipy.stats as st

#pd.set_option("display.max_rows", None, "display.max_columns", None)
pd.reset_option('all')

from allensdk.core.brain_observatory_cache import BrainObservatoryCache
import pprint
import allensdk.brain_observatory.stimulus_info as stim_info
from allensdk.brain_observatory.drifting_gratings import DriftingGratings



boc = BrainObservatoryCache()

exp_test = boc.get_ophys_experiments(cre_lines=['Vip-IRES-Cre'], stimuli=['drifting_gratings'], 
                                     targeted_structures=['VISp'])
print("Experiments for test: %d\n" % (len(exp_test)))

# Download experiment containers for VISp experiments
visal_ecs = boc.get_experiment_containers(targeted_structures=['VISal'])
print("all VISal experiment containers: %d" % len(visal_ecs))

# Download experiment containers for VISp experiments
visam_ecs = boc.get_experiment_containers(targeted_structures=['VISam'])
print("all VISam experiment containers: %d" % len(visam_ecs))

# Download experiment containers for VISp experiments
visl_ecs = boc.get_experiment_containers(targeted_structures=['VISl'])
print("all VISl experiment containers: %d" % len(visl_ecs))

# Download experiment containers for VISp experiments
visp_ecs = boc.get_experiment_containers(targeted_structures=['VISp'])
print("all VISp experiment containers: %d" % len(visp_ecs))

# Download experiment containers for VISp experiments
vispm_ecs = boc.get_experiment_containers(targeted_structures=['VISpm'])
print("all VISpm experiment containers: %d" % len(vispm_ecs))

# Download experiment containers for VISp experiments
visrl_ecs = boc.get_experiment_containers(targeted_structures=['VISrl'])
print("all VISrl experiment containers: %d" % len(visrl_ecs))



session_id0 = exp_test[0]['id']
print(session_id0)

data_set0 = boc.get_ophys_experiment_data(session_id0)
pprint.pprint(data_set0.get_metadata())

#Stimulus Table
drifting_gratings_table0 = data_set0.get_stimulus_table("drifting_gratings")
drifting_gratings_table0



vip_inter_ecs = boc.get_experiment_containers(cre_lines=['VI-IRES-Cre'])
# Download cells for a set of experiments and convert to DataFrame
cells = boc.get_cell_specimens()
cells = pd.DataFrame.from_records(cells)
print("total cells: %d" % len(cells))

# find direction selective cells in VISp
vip_inter_ec_ids = [ ec['id'] for ec in vip_inter_ecs ]
vip_inter_cells = cells[cells['experiment_container_id'].isin(vip_inter_ec_ids)]
print("VIP Interneuron cells: %d" % len(vip_inter_cells))

# significant response to drifting gratings stimulus
sig_cells = vip_inter_cells[vip_inter_cells['p_dg'] < 0.05]
print("cells with sig. response to drifting gratings: %d" % len(sig_cells))

# direction selective cells
dsi_cells = sig_cells[(sig_cells['g_dsi_dg'] > 0.9)]
print("direction-selective cells: %d" % len(dsi_cells))

# find experiment containers for those cells
dsi_ec_ids = dsi_cells['experiment_container_id'].unique()
print("total dsi experiment containers: %d" % len(dsi_ec_ids))

# Download the ophys experiments containing the drifting gratings stimulus for VISp experiment containers
dsi_exps = boc.get_ophys_experiments(experiment_container_ids=dsi_ec_ids, stimuli=[stim_info.DRIFTING_GRATINGS])
print("VIP Interneuron drifting gratings ophys experiments: %d" % len(dsi_exps))



def get_unique_orientations(dg_table):

    pre_ORIs = dg_table['orientation'].unique() 
    ORIs = [x for x in pre_ORIs if np.isnan(x) == False]
    return ORIs

def get_unique_temporal_frequencies(dg_table):

    pre_TFs = dg_table['temporal_frequency'].unique()
    TFs = [x for x in pre_TFs if np.isnan(x) == False]
    return TFs

def get_condition_trials(dg_table, ori, tf):
    trials_in_condition = (dg_table['orientation'] == ori) & (dg_table['temporal_frequency'] == tf)
        
    condition_trial_indices = np.argwhere(trials_in_condition)
     
    just_indices = []
    for sublist in condition_trial_indices:
        just_indices.append(sublist[0])
        
    return just_indices

def get_blank_trials(dg_table):
    for ori_idx, current_ori in enumerate(get_unique_orientations(dg_table)):
        for TF_idx, current_tf in enumerate(get_unique_temporal_frequencies(dg_table)):
            trials_in_condition = (np.isnan(dg_table['orientation'])) & (np.isnan(dg_table['temporal_frequency']))
        
    condition_trial_indices = np.argwhere(trials_in_condition)
     
    just_indices = []
    for sublist in condition_trial_indices:
        just_indices.append(sublist[0])
        
    return just_indices

def get_condition_mean(dg_table,ORIs,TFs,i,j,neuron_number,dg_mean_sweeps):
    return np.nanmean(dg_mean_sweeps.iloc[get_condition_trials(dg_table, ORIs[i], TFs[j]),neuron_number])

def get_blank_mean(dg_table, neuron_number,dg_mean_sweeps):
    return np.mean(dg_mean_sweeps.iloc[get_blank_trials(dg_table),neuron_number])

def get_response_matrix(dg_table, current_neuron, dg_mean_sweep_responses, threshold):
    sorted_dg_table = dg_table.sort_values(by=['temporal_frequency','orientation'])
    all_unique_orientations = get_unique_orientations(sorted_dg_table)
    all_unique_temporal_frequencies = get_unique_temporal_frequencies(sorted_dg_table)
    
#     pre_matrix = np.zeros((len(all_unique_orientations), len(all_unique_temporal_frequencies)))
    
#     for i in range(len(all_unique_orientations)):
#         for j in range(0, len(all_unique_temporal_frequencies)):
#             cur_condition_response = get_condition_mean(dg_table,all_unique_orientations,all_unique_temporal_frequencies,i,j,current_neuron,dg_mean_sweep_responses)
#             if cur_condition_response <= threshold:
#                 pre_matrix[i, j] = 1
                
    matrix = np.zeros(len(all_unique_temporal_frequencies))
    
    for i in range(len(all_unique_orientations)):
        for j in range(len(all_unique_temporal_frequencies)):
            cur_condition_response = get_condition_mean(dg_table,all_unique_orientations,all_unique_temporal_frequencies,i,j,current_neuron,dg_mean_sweep_responses)
            if cur_condition_response <= threshold:
                matrix[j] = matrix[j] + 1
    
    
                
    return matrix

def bootstrap(num_shuffles, cell_responses, total_neurons, ori_idx, avg): 
    shuffle_dist =  np.zeros(num_shuffles)
    for i_shuffle in range(num_shuffles):
        shuffle_dist[i_shuffle] = np.mean(cell_responses[ori_idx][np.random.choice(total_neurons,size=(total_neurons,))])
        
    low_lim = [np.percentile(shuffle_dist, 5)] - np.array([avg])
    up_lim = [np.percentile(shuffle_dist, 95)] - np.array([avg])
       
    return np.ndarray.flatten(np.absolute(np.vstack((low_lim, up_lim))))

# cell_responses = [1,2,3,3,3,4,5,6,7,7,7,8]
# cell_responses

# np.mean(cell_responses[np.random.choice(total_neurons,size=(total_neurons,))])

def get_first_ten_experiment_tuning_curves(exp_array):
    for cur_exp in range(10):
        dg_tuning_curve_wip(cur_exp, exp_array)

def get_all_experiment_tuning_curves(exp_array):
    for cur_exp in range(len(exp_array)):
        dg_tuning_curve_wip(cur_exp, exp_array)



def chisq_from_stim_table(stim_table,
                          columns,
                          mean_sweep_events,
                          num_shuffles=1000,
                          verbose=False):
    #  stim_table is a pandas DataFrame with len = num_sweeps
    #  columns is a list of column names that define the categories (e.g. ['Ori','Contrast'])
    #  mean_sweep_events is a numpy array with shape (num_sweeps,num_cells)
    
    sweep_categories = stim_table_to_categories(stim_table,columns,verbose=verbose)
    p_vals = compute_chi_shuffle(mean_sweep_events,sweep_categories,num_shuffles=num_shuffles)
    
    return p_vals

def compute_chi_shuffle(mean_sweep_events,
                        sweep_categories,
                        num_shuffles=1000):

    #  mean_sweep_events is a numpy array with shape (num_sweeps,num_cells)
    #  sweep_conditions is a numpy array with shape (num_sweeps)
    #       sweep_conditions gives the category label for each sweep
    
    (num_sweeps,num_cells) = np.shape(mean_sweep_events) 
    
    assert len(sweep_categories) == num_sweeps
    
    sweep_categories_dummy = make_category_dummy(sweep_categories)
    
    expected = compute_expected(mean_sweep_events,sweep_categories_dummy)
    observed = compute_observed(mean_sweep_events,sweep_categories_dummy)
    chi_actual = compute_chi(observed,expected)
    
    chi_shuffle = np.zeros((num_cells,num_shuffles))
    for ns in range(num_shuffles):
        #print 'shuffle ' + str(ns+1) + ' of ' + str(num_shuffles)
        
        shuffle_sweeps = np.random.choice(num_sweeps,size=(num_sweeps,))
        shuffle_sweep_events = mean_sweep_events[shuffle_sweeps]
        
        shuffle_expected = compute_expected(shuffle_sweep_events,sweep_categories_dummy)
        shuffle_observed = compute_observed(shuffle_sweep_events,sweep_categories_dummy)
        
        chi_shuffle[:,ns] = compute_chi(shuffle_observed,shuffle_expected)
    
    p_vals = np.mean(chi_actual.reshape(num_cells,1)<chi_shuffle,axis=1)
    
    return p_vals

def stim_table_to_categories(stim_table,
                             columns,
                             verbose=False):
    # get the categories for all sweeps with each unique combination of 
    #   parameters in 'columns' being one category
    # sweeps with non-finite values in ANY column (e.g. np.NaN) are labeled 
    #   as blank sweeps (category = -1)
    
    num_sweeps = len(stim_table)
    num_params = len(columns)
    
    unique_params = []
    options_per_column = []
    max_combination = 1
    for column in columns:
        column_params = np.unique(stim_table[column].values)
        column_params = column_params[np.isfinite(column_params)]
        unique_params.append(column_params)
        options_per_column.append(len(column_params))
        max_combination*=len(column_params)

    category = 0
    sweep_categories = -1*np.ones((num_sweeps,))
    curr_combination = np.zeros((num_params,),dtype=np.int)
    options_per_column = np.array(options_per_column).astype(np.int)
    all_tried = False
    while not all_tried:
        
        matches_combination = np.ones((num_sweeps,),dtype=np.bool)
        for i_col,column in enumerate(columns):
            param = unique_params[i_col][curr_combination[i_col]]
            matches_param = stim_table[column].values == param
            matches_combination *= matches_param
            
        if np.any(matches_combination):
            sweep_categories[matches_combination] = category
            if verbose:
                print ('Category ' + str(category))
                for i_col,column in enumerate(columns):
                    param = unique_params[i_col][curr_combination[i_col]]
                    print (column + ': ' + str(param))
            
            category+=1
              
        #advance the combination
        curr_combination = advance_combination(curr_combination,options_per_column)
        all_tried = curr_combination[0]==options_per_column[0]
    
    if verbose:    
        blank_sweeps = sweep_categories==-1
        print ('num blank: ' + str(blank_sweeps.sum()))
        
    return sweep_categories
    
def advance_combination(curr_combination,
                        options_per_column):
    
    num_cols = len(curr_combination)
    
    might_carry = True
    col = num_cols-1
    while might_carry:
        curr_combination[col] += 1
        if col==0 or curr_combination[col]<options_per_column[col]:
            might_carry = False
        else:
            curr_combination[col] = 0
            col-=1
            
    return curr_combination
    

def make_category_dummy(sweep_categories):
    #makes a dummy variable version of the sweep category list
    
    num_sweeps = len(sweep_categories)
    categories = np.unique(sweep_categories)
    num_categories = len(categories)
    
    sweep_category_mat = np.zeros((num_sweeps,num_categories),dtype=np.bool)
    for i_cat,category in enumerate(categories):
        category_idx = np.argwhere(sweep_categories==category)[:,0]
        sweep_category_mat[category_idx,i_cat] = True
    
    return sweep_category_mat

def compute_observed(mean_sweep_events,sweep_conditions):

    (num_sweeps,num_conditions) = np.shape(sweep_conditions)
    num_cells = np.shape(mean_sweep_events)[1]   
    
    observed_mat = (mean_sweep_events.T).reshape(num_cells,num_sweeps,1) * sweep_conditions.reshape(1,num_sweeps,num_conditions)
    observed = np.sum(observed_mat,axis=1)
    
    return observed
    
def compute_expected(mean_sweep_events,sweep_conditions):   
    
    num_conditions = np.shape(sweep_conditions)[1]
    num_cells = np.shape(mean_sweep_events)[1]
    
    sweeps_per_condition = np.sum(sweep_conditions,axis=0)
    events_per_sweep = np.mean(mean_sweep_events,axis=0)
    
    expected = sweeps_per_condition.reshape(1,num_conditions) * events_per_sweep.reshape(num_cells,1) 
    
    return expected

def compute_chi(observed,expected):

    chi = (observed - expected) ** 2 /expected
    chi = np.where(expected>0,chi,0.0)  
    return np.sum(chi,axis=1)

def dg_tuning_curve_wip(exp_number, exp_array): 
    
    dsi_cell = exp_array.iloc[exp_number]
    cell_exp = boc.get_ophys_experiments(cell_specimen_ids=[dsi_cell['cell_specimen_id']],stimuli=[stim_info.DRIFTING_GRATINGS])[0]
    data_set = boc.get_ophys_experiment_data(cell_exp['id'])

    dg = DriftingGratings(data_set)
    dg_peak = dg.peak
    
    dg_tbl = data_set.get_stimulus_table("drifting_gratings")
    dg_columns = list(dg_tbl.columns[0:2])
    dg_mean_sweep_events = dg.mean_sweep_response.iloc[:,:-1]
    total_neurons = dg_mean_sweep_events.shape[1]
    threshold = 0
    p_vals = chisq_from_stim_table(dg_tbl, dg_columns, dg_mean_sweep_events.values, num_shuffles=1000, verbose=False)
    all_cell_responses =  np.zeros(((len(dg.tfvals) - 1), total_neurons))
    num_shuffles = 1000

    
   
        #all_cell_responses = all_cell_responses + response_matrix
        
    #avg_cell_responses = all_cell_responses / total_neurons


    for cur_neuron in range(total_neurons):
        #Get Response Matrix
        response_matrix = get_response_matrix(dg_tbl, cur_neuron, dg_mean_sweep_events, threshold)        
        all_cell_responses[:,cur_neuron] = response_matrix
        
        avg_cell_responses = np.zeros(len(dg.tfvals) - 1)
        bootstraps = np.zeros((2, (len(dg.tfvals) - 1)))

        


    for i_ori in range((len(dg.tfvals) - 1)):
        avg_cell_responses[i_ori]=np.mean(all_cell_responses[i_ori,:])
        bootstraps[:,i_ori] = bootstrap(num_shuffles, all_cell_responses, total_neurons, i_ori, avg_cell_responses[i_ori])
#it wont accept all_cell_responses[i_ori] because bootstrap function breaks when given single array, 
#needs to take single row of 2d matrix

    fig, ax2  = plt.subplots()
    #print(str(bootstraps))
    # plot orientation selectivity
    ax2.errorbar(dg.tfvals[1:],avg_cell_responses, yerr=bootstraps, ecolor='black')
    ax2.set_xlabel('Temporal Frequencies')
    ax2.set_ylabel('Negative Reponse Orientations')
    ax2.set_xticks(dg.tfvals)
    ax2.set_xticklabels(dg.tfvals)
    ax2.set_yticks(np.arange(len(dg.orivals)+1))
    ax2.set_yticklabels(range(len(dg.orivals) + 1))
    ax2.set_title('Average Error Bar Plot of Negative Orientation Selective Cell Responses')

    plt.savefig('tuning_graph_images/VIP_threshold_selectivity/threshold_error_bar_plot.png', transparent=True)
    #plt.savefig('tuning_graph_images/experiment' + str(exp_number) + '/neuron' + str(cur_neuron) + '_tuning_graph.png', transparent=True)
    plt.show



def get_all_experiment_neurons(exp_array): 
    ogArr = []
    for i_exp in exp_array:
    
        dsi_cell = exp_array[i_exp]
        cell_exp = boc.get_ophys_experiments(cell_specimen_ids=[dsi_cell['cell_specimen_id']],stimuli=[stim_info.DRIFTING_GRATINGS])[0]
        data_set = boc.get_ophys_experiment_data(cell_exp['id'])

        dg = DriftingGratings(data_set)
        dg_peak = dg.peak

        dg_tbl = data_set.get_stimulus_table("drifting_gratings")
        dg_columns = list(dg_tbl.columns[0:2])
        dg_mean_sweep_events = dg.mean_sweep_response.iloc[:,:-1]
        total_neurons = dg_mean_sweep_events.shape[1]
        threshold = 0
        p_vals = chisq_from_stim_table(dg_tbl, dg_columns, dg_mean_sweep_events.values, num_shuffles=1000, verbose=False)
        all_cell_responses =  np.zeros(((len(dg.tfvals) - 1), total_neurons))
        num_shuffles = 1000

        for cur_neuron in range(total_neurons):
            #Get Response Matrix
            response_matrix = get_response_matrix(dg_tbl, cur_neuron, dg_mean_sweep_events, threshold)        
            all_cell_responses[:,cur_neuron] = response_matrix
        
        ogArr = np.append(ogArr, all_cell_responses, axis=1)
        
    return ogArr

def dg_tuning_curve(exp_array): 
    all_neuron_responses = get_all_experiment_neurons(exp_array)
    
    avg_cell_responses = np.zeros(len(dg.tfvals) - 1)
    bootstraps = np.zeros((2, (len(dg.tfvals) - 1)))

    for i_ori in range((len(dg.tfvals) - 1)):
        avg_cell_responses[i_ori]=np.mean(all_neuron_responses[i_ori,:])
        bootstraps[:,i_ori] = bootstrap(num_shuffles, all_neuron_responses, total_neurons, i_ori, avg_cell_responses[i_ori])
    #it wont accept all_cell_responses[i_ori] because bootstrap function breaks when given single array, 
    #needs to take single row of 2d matrix

    fig, ax2  = plt.subplots()
    #print(str(bootstraps))
    # plot orientation selectivity
    ax2.errorbar(dg.tfvals[1:],avg_cell_responses, yerr=bootstraps, ecolor='black')
    ax2.set_xlabel('Temporal Frequencies')
    ax2.set_ylabel('Negative Reponse Orientations')
    ax2.set_xticks(dg.tfvals)
    ax2.set_xticklabels(dg.tfvals)
    ax2.set_yticks(np.arange(len(dg.orivals)+1))
    ax2.set_yticklabels(range(len(dg.orivals) + 1))
    ax2.set_title('Average Error Bar Plot of Negative Orientation Selective Cell Responses')
    all_neuron_responses
    
    plt.savefig('tuning_graph_images/VIP_threshold_selectivity/threshold_error_bar_plot.png', transparent=True)
    #plt.savefig('tuning_graph_images/experiment' + str(exp_number) + '/neuron' + str(cur_neuron) + '_tuning_graph.png', transparent=True)
    plt.show


#plot tuning curve for all cells in given experiment (experiment = 5)
dg_tuning_curve_wip(5, dsi_cells)

get_all_experiment_neurons(dsi_cells)
