#Imports
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
%matplotlib inline
import matplotlib.ticker as ticker
import os
import scipy.stats as st

pd.set_option("display.max_rows", None, "display.max_columns", None)
np.set_printoptions(threshold=np.inf)
#pd.reset_option('all')

from allensdk.core.brain_observatory_cache import BrainObservatoryCache
import pprint
import allensdk.brain_observatory.stimulus_info as stim_info
from allensdk.brain_observatory.drifting_gratings import DriftingGratings



boc = BrainObservatoryCache()

# Download a list of all cre driver lines 
cre_lines = boc.get_all_cre_lines()
print("all cre lines:\n")
pprint.pprint(cre_lines)

exp_test = boc.get_ophys_experiments(cre_lines=['Vip-IRES-Cre'], stimuli=['drifting_gratings'], 
                                     targeted_structures=['VISp'])
print("Experiments for test: %d\n" % (len(exp_test)))

# Download experiment containers for VISp experiments
visal_ecs = boc.get_experiment_containers(targeted_structures=['VISal'])
print("all VISal experiment containers: %d" % len(visal_ecs))

# Download experiment containers for VISp experiments
visam_ecs = boc.get_experiment_containers(targeted_structures=['VISam'])
print("all VISam experiment containers: %d" % len(visam_ecs))

# Download experiment containers for VISp experiments
visl_ecs = boc.get_experiment_containers(targeted_structures=['VISl'])
print("all VISl experiment containers: %d" % len(visl_ecs))

# Download experiment containers for VISp experiments
visp_ecs = boc.get_experiment_containers(targeted_structures=['VISp'])
print("all VISp experiment containers: %d" % len(visp_ecs))

# Download experiment containers for VISp experiments
vispm_ecs = boc.get_experiment_containers(targeted_structures=['VISpm'])
print("all VISpm experiment containers: %d" % len(vispm_ecs))

# Download experiment containers for VISp experiments
visrl_ecs = boc.get_experiment_containers(targeted_structures=['VISrl'])
print("all VISrl experiment containers: %d" % len(visrl_ecs))

#cell_exp = boc.get_ophys_experiments(cell_specimen_ids=[i_exp['cell_specimen_id']],stimuli=[stim_info.DRIFTING_GRATINGS])[0]
#data_set = boc.get_ophys_experiment_data(cell_exp['id'])


session_id0 = exp_test[0]['id']
print(session_id0)

data_set0 = boc.get_ophys_experiment_data(session_id0)
pprint.pprint(data_set0.get_metadata())
dg0 = DriftingGratings(data_set0)


#Stimulus Table
drifting_gratings_table0 = data_set0.get_stimulus_table("drifting_gratings")
drifting_gratings_table0

len(dg0.cell_id)







vip_inter_ecs = boc.get_experiment_containers(cre_lines=['VIP-IRES-Cre'])
# Download cells for a set of experiments and convert to DataFrame
cells = boc.get_cell_specimens()
cells = pd.DataFrame.from_records(cells)
print("total cells: %d" % len(cells))

# find direction selective cells in VISp
vip_inter_ec_ids = [ ec['id'] for ec in vip_inter_ecs ]
vip_inter_cells = cells[cells['experiment_container_id'].isin(vip_inter_ec_ids)]
print("VIP Interneuron cells: %d" % len(vip_inter_cells))

# significant response to drifting gratings stimulus
sig_cells = vip_inter_cells[vip_inter_cells['p_dg'] < 0.05]
print("cells with sig. response to drifting gratings: %d" % len(sig_cells))

# direction selective cells
dsi_cells = sig_cells[(sig_cells['g_dsi_dg'] > 0.9)]
print("direction-selective cells: %d" % len(dsi_cells))

# find experiment containers for those cells
dsi_ec_ids = dsi_cells['experiment_container_id'].unique()
print("total dsi experiment containers: %d" % len(dsi_ec_ids))

# Download the ophys experiments containing the drifting gratings stimulus for VISp experiment containers
dsi_exps = boc.get_ophys_experiments(experiment_container_ids=dsi_ec_ids, stimuli=[stim_info.DRIFTING_GRATINGS])
print("VIP Interneuron drifting gratings ophys experiments: %d" % len(dsi_exps))

def get_unique_orientations(dg_table):

    pre_ORIs = dg_table['orientation'].unique() 
    ORIs = [x for x in pre_ORIs if np.isnan(x) == False]
    return ORIs

def get_unique_temporal_frequencies(dg_table):

    pre_TFs = dg_table['temporal_frequency'].unique()
    TFs = [x for x in pre_TFs if np.isnan(x) == False]
    return TFs

def get_condition_trials(dg_table, ori, tf):
    trials_in_condition = (dg_table['orientation'] == ori) & (dg_table['temporal_frequency'] == tf)
        
    condition_trial_indices = np.argwhere(trials_in_condition)
     
    just_indices = []
    for sublist in condition_trial_indices:
        just_indices.append(sublist[0])
        
    return just_indices

def get_blank_trials(dg_table):
    for ori_idx, current_ori in enumerate(get_unique_orientations(dg_table)):
        for TF_idx, current_tf in enumerate(get_unique_temporal_frequencies(dg_table)):
            trials_in_condition = (np.isnan(dg_table['orientation'])) & (np.isnan(dg_table['temporal_frequency']))
        
    condition_trial_indices = np.argwhere(trials_in_condition)
     
    just_indices = []
    for sublist in condition_trial_indices:
        just_indices.append(sublist[0])
        
    return just_indices

def get_condition_mean(dg_table,ORIs,TFs,i,j,neuron_number,dg_mean_sweeps):
    return np.nanmean(dg_mean_sweeps.iloc[get_condition_trials(dg_table, ORIs[i], TFs[j]),neuron_number])

def get_blank_mean(dg_table, neuron_number,dg_mean_sweeps):
    return np.mean(dg_mean_sweeps.iloc[get_blank_trials(dg_table),neuron_number])

def get_condition_response_matrix(dg_table, current_neuron, dg_mean_sweep_responses):
    sorted_dg_table = dg_table.sort_values(by=['temporal_frequency','orientation'])
    all_unique_orientations = get_unique_orientations(sorted_dg_table)
    all_unique_temporal_frequencies = get_unique_temporal_frequencies(sorted_dg_table)
    
    matrix = np.zeros((len(all_unique_orientations), len(all_unique_temporal_frequencies) + 1))
    matrix[0,0] = get_blank_mean(dg_table, current_neuron, dg_mean_sweep_responses)
    matrix[1:len(all_unique_orientations),0] = float('nan')
    
    for i in range(len(all_unique_orientations)):
        for j in range(0, len(all_unique_temporal_frequencies)):
            matrix[i, j+1] = get_condition_mean(dg_table,all_unique_orientations,all_unique_temporal_frequencies,i,j,current_neuron,dg_mean_sweep_responses)
        
    return matrix

def get_response_matrix(dg_table, current_neuron, dg_mean_sweep_responses, threshold, condition_significances):
    sorted_dg_table = dg_table.sort_values(by=['temporal_frequency','orientation'])
    all_unique_orientations = get_unique_orientations(sorted_dg_table)
    all_unique_temporal_frequencies = get_unique_temporal_frequencies(sorted_dg_table)
    
#     pre_matrix = np.zeros((len(all_unique_orientations), len(all_unique_temporal_frequencies)))
    
#     for i in range(len(all_unique_orientations)):
#         for j in range(0, len(all_unique_temporal_frequencies)):
#             cur_condition_response = get_condition_mean(dg_table,all_unique_orientations,all_unique_temporal_frequencies,i,j,current_neuron,dg_mean_sweep_responses)
#             if cur_condition_response <= threshold:
#                 pre_matrix[i, j] = 1
                
    matrix = np.zeros(len(all_unique_temporal_frequencies))
    
    for i in range(len(all_unique_orientations)):
        for j in range(len(all_unique_temporal_frequencies)):
            cur_condition_response = condition_significances[j,i]
            if cur_condition_response <= threshold:
                matrix[j] = matrix[j] + 1
    
    
                
    return matrix

def get_response_matrix2(dg_table, current_neuron, dg_mean_sweep_responses, threshold, condition_significances):
    sorted_dg_table = dg_table.sort_values(by=['temporal_frequency','orientation'])
    all_unique_orientations = get_unique_orientations(sorted_dg_table)
    all_unique_temporal_frequencies = get_unique_temporal_frequencies(sorted_dg_table)
    
#     pre_matrix = np.zeros((len(all_unique_orientations), len(all_unique_temporal_frequencies)))
    
#     for i in range(len(all_unique_orientations)):
#         for j in range(0, len(all_unique_temporal_frequencies)):
#             cur_condition_response = get_condition_mean(dg_table,all_unique_orientations,all_unique_temporal_frequencies,i,j,current_neuron,dg_mean_sweep_responses)
#             if cur_condition_response <= threshold:
#                 pre_matrix[i, j] = 1
                
    matrix = np.zeros(len(all_unique_temporal_frequencies))
    
    for i in range(len(all_unique_orientations)):
        for j in range(len(all_unique_temporal_frequencies)):
            cur_condition_response = condition_significances[j,i]
            if cur_condition_response >= 1 - threshold:
                matrix[j] = matrix[j] + 1
    
    
                
    return matrix

def get_response_matrix3(threshold, condition_significances):
 
    return condition_significances <= threshold

def bootstrap(num_shuffles, cell_responses, total_neurons, ori_idx, avg): 
    shuffle_dist =  np.zeros(num_shuffles)
    for i_shuffle in range(num_shuffles):
        shuffle_dist[i_shuffle] = np.mean(cell_responses[ori_idx][np.random.choice(total_neurons,size=(total_neurons,))])
        
    low_lim = [np.percentile(shuffle_dist, 5)] - np.array([avg])
    up_lim = [np.percentile(shuffle_dist, 95)] - np.array([avg])
       
    return np.ndarray.flatten(np.absolute(np.vstack((low_lim, up_lim))))

def null_distribution_bootstrap(num_shuffles, cell_responses, num_blanks, trials, all_condition_means): 
    null_dist = np.mean(cell_responses[np.random.choice(num_blanks,size=(num_shuffles,trials))], axis = 1)
    all_percentiles =  np.zeros(len(all_condition_means))

    for i, condition_mean in enumerate(all_condition_means):
        resp_above_null = null_dist < condition_mean 
        percentile = resp_above_null.mean()
        
        all_percentiles[i] = percentile
       
    return all_percentiles

def get_null_matrix(dg_tbl, current_neuron, mean_sweeps, shuffles): 
    
    rm = get_condition_response_matrix(dg_tbl, current_neuron, mean_sweeps)
    blank_events = mean_sweeps.iloc[get_blank_trials(dg_tbl),current_neuron].values
    
    pre_means_list = np.ndarray.flatten(rm)
    pre_means_list[0] = float('nan')
    means_list = [x for x in pre_means_list if np.isnan(x) == False]
    null_dist = null_distribution_bootstrap(shuffles, blank_events, len(blank_events), 15, means_list).reshape(5, 8)
    
    return null_dist





def chisq_from_stim_table(stim_table,
                          columns,
                          mean_sweep_events,
                          num_shuffles=1000,
                          verbose=False):
    #  stim_table is a pandas DataFrame with len = num_sweeps
    #  columns is a list of column names that define the categories (e.g. ['Ori','Contrast'])
    #  mean_sweep_events is a numpy array with shape (num_sweeps,num_cells)
    
    sweep_categories = stim_table_to_categories(stim_table,columns,verbose=verbose)
    p_vals = compute_chi_shuffle(mean_sweep_events,sweep_categories,num_shuffles=num_shuffles)
    
    return p_vals

def compute_chi_shuffle(mean_sweep_events,
                        sweep_categories,
                        num_shuffles=1000):

    #  mean_sweep_events is a numpy array with shape (num_sweeps,num_cells)
    #  sweep_conditions is a numpy array with shape (num_sweeps)
    #       sweep_conditions gives the category label for each sweep
    
    (num_sweeps,num_cells) = np.shape(mean_sweep_events) 
    
    assert len(sweep_categories) == num_sweeps
    
    sweep_categories_dummy = make_category_dummy(sweep_categories)
    
    expected = compute_expected(mean_sweep_events,sweep_categories_dummy)
    observed = compute_observed(mean_sweep_events,sweep_categories_dummy)
    chi_actual = compute_chi(observed,expected)
    
    chi_shuffle = np.zeros((num_cells,num_shuffles))
    for ns in range(num_shuffles):
        #print 'shuffle ' + str(ns+1) + ' of ' + str(num_shuffles)
        
        shuffle_sweeps = np.random.choice(num_sweeps,size=(num_sweeps,))
        shuffle_sweep_events = mean_sweep_events[shuffle_sweeps]
        
        shuffle_expected = compute_expected(shuffle_sweep_events,sweep_categories_dummy)
        shuffle_observed = compute_observed(shuffle_sweep_events,sweep_categories_dummy)
        
        chi_shuffle[:,ns] = compute_chi(shuffle_observed,shuffle_expected)
    
    p_vals = np.mean(chi_actual.reshape(num_cells,1)<chi_shuffle,axis=1)
    
    return p_vals

def stim_table_to_categories(stim_table,
                             columns,
                             verbose=False):
    # get the categories for all sweeps with each unique combination of 
    #   parameters in 'columns' being one category
    # sweeps with non-finite values in ANY column (e.g. np.NaN) are labeled 
    #   as blank sweeps (category = -1)
    
    num_sweeps = len(stim_table)
    num_params = len(columns)
    
    unique_params = []
    options_per_column = []
    max_combination = 1
    for column in columns:
        column_params = np.unique(stim_table[column].values)
        column_params = column_params[np.isfinite(column_params)]
        unique_params.append(column_params)
        options_per_column.append(len(column_params))
        max_combination*=len(column_params)

    category = 0
    sweep_categories = -1*np.ones((num_sweeps,))
    curr_combination = np.zeros((num_params,),dtype=np.int)
    options_per_column = np.array(options_per_column).astype(np.int)
    all_tried = False
    while not all_tried:
        
        matches_combination = np.ones((num_sweeps,),dtype=np.bool)
        for i_col,column in enumerate(columns):
            param = unique_params[i_col][curr_combination[i_col]]
            matches_param = stim_table[column].values == param
            matches_combination *= matches_param
            
        if np.any(matches_combination):
            sweep_categories[matches_combination] = category
            if verbose:
                print ('Category ' + str(category))
                for i_col,column in enumerate(columns):
                    param = unique_params[i_col][curr_combination[i_col]]
                    print (column + ': ' + str(param))
            
            category+=1
              
        #advance the combination
        curr_combination = advance_combination(curr_combination,options_per_column)
        all_tried = curr_combination[0]==options_per_column[0]
    
    if verbose:    
        blank_sweeps = sweep_categories==-1
        print ('num blank: ' + str(blank_sweeps.sum()))
        
    return sweep_categories
    
def advance_combination(curr_combination,
                        options_per_column):
    
    num_cols = len(curr_combination)
    
    might_carry = True
    col = num_cols-1
    while might_carry:
        curr_combination[col] += 1
        if col==0 or curr_combination[col]<options_per_column[col]:
            might_carry = False
        else:
            curr_combination[col] = 0
            col-=1
            
    return curr_combination
    

def make_category_dummy(sweep_categories):
    #makes a dummy variable version of the sweep category list
    
    num_sweeps = len(sweep_categories)
    categories = np.unique(sweep_categories)
    num_categories = len(categories)
    
    sweep_category_mat = np.zeros((num_sweeps,num_categories),dtype=np.bool)
    for i_cat,category in enumerate(categories):
        category_idx = np.argwhere(sweep_categories==category)[:,0]
        sweep_category_mat[category_idx,i_cat] = True
    
    return sweep_category_mat

def compute_observed(mean_sweep_events,sweep_conditions):

    (num_sweeps,num_conditions) = np.shape(sweep_conditions)
    num_cells = np.shape(mean_sweep_events)[1]   
    
    observed_mat = (mean_sweep_events.T).reshape(num_cells,num_sweeps,1) * sweep_conditions.reshape(1,num_sweeps,num_conditions)
    observed = np.sum(observed_mat,axis=1)
    
    return observed
    
def compute_expected(mean_sweep_events,sweep_conditions):   
    
    num_conditions = np.shape(sweep_conditions)[1]
    num_cells = np.shape(mean_sweep_events)[1]
    
    sweeps_per_condition = np.sum(sweep_conditions,axis=0)
    events_per_sweep = np.mean(mean_sweep_events,axis=0)
    
    expected = sweeps_per_condition.reshape(1,num_conditions) * events_per_sweep.reshape(num_cells,1) 
    
    return expected

def compute_chi(observed,expected):

    chi = (observed - expected) ** 2 /expected
    chi = np.where(expected>0,chi,0.0)  
    return np.sum(chi,axis=1)

#add all the index values from 2d matirx and divide by total to get 40 by 40 tunicg curve for cre line

def get_all_experiment_neurons(cre):
    
    og_arr  = np.empty((0, (len(dg0.tfvals) - 1)), int)
    TF_SbC_tuning = np.array(og_arr).T   
    cell_exp = boc.get_ophys_experiments(cre_lines=[cre], stimuli=['drifting_gratings'])
    
    for i_exp in cell_exp:

        data_set = boc.get_ophys_experiment_data(i_exp['id'])
        dg = DriftingGratings(data_set)
        dg_peak = dg.peak

        dg_tbl = data_set.get_stimulus_table("drifting_gratings")
        dg_columns = list(dg_tbl.columns[0:2])
        dg_mean_sweep_events = dg.mean_sweep_response.iloc[:,:-1]
        total_neurons = dg_mean_sweep_events.shape[1]
        threshold = 0.025
        shuffles = 10000
        all_cell_responses =  np.zeros(((len(dg.tfvals) - 1), total_neurons))

        for cur_neuron in range(total_neurons):
            #Get Response Matrix
            cur_condition_sig = get_null_matrix(dg_tbl, cur_neuron, dg_mean_sweep_events, shuffles)

            response_matrix = get_response_matrix(dg_tbl, cur_neuron, dg_mean_sweep_events, threshold, cur_condition_sig)        
            all_cell_responses[:,cur_neuron] = response_matrix

        TF_SbC_tuning = np.append(TF_SbC_tuning, all_cell_responses, axis=1)

    return TF_SbC_tuning

vip_cells = get_all_experiment_neurons(vip_cre)

sst_cells = get_all_experiment_neurons(sst_cre)

nr5_cells = get_all_experiment_neurons(nr5_cre)

def dg_tuning_curve(all_neuron_responses, cre): 
    #all_neuron_responses = get_all_experiment_neurons(exp_array)
    name = cre[:3]
    avg_cell_responses = np.zeros((len(dg0.tfvals) - 1))
    bootstraps = np.zeros((2, (len(dg0.tfvals) - 1)))
    num_shuffles = 1000
    total_neurons = all_neuron_responses.shape[1]
    threshold = 0.05


    for i_ori in range((len(dg0.tfvals) - 1)):
        avg_cell_responses[i_ori]=np.mean(all_neuron_responses[i_ori,:])
        bootstraps[:,i_ori] = bootstrap(num_shuffles, all_neuron_responses, total_neurons, i_ori, avg_cell_responses[i_ori])
    #it wont accept all_cell_responses[i_ori] because bootstrap function breaks when given single array, 
    #needs to take single row of 2d matrix

    fig, ax2  = plt.subplots()
    #print(str(bootstraps))
    # plot orientation selectivity
    normalized_x = np.log(dg0.tfvals[1:])
    ax2.errorbar(normalized_x, avg_cell_responses, yerr=bootstraps, ecolor='black')
    ax2.set_xlabel('Temporal Frequencies')
    ax2.set_ylabel('Negative Response Orientations')
    ax2.set_xticks(normalized_x)
    ax2.set_xticklabels(dg0.tfvals[1:])
    ax2.set_yticks(np.arange(len(dg0.orivals)+1))
    ax2.set_yticklabels(range(len(dg0.orivals) + 1))
    
#     ax2.set_title(name + ' Average Error Bar Plot of Negative Orientation Selective Cell Responses')
#     plt.savefig('tuning_graph_images/' + name + '_threshold_selectivity/threshold_error_bar_plot.png', transparent=True)
    
    ax2.set_title(name + ' Error Bar Plot of Suppressed Responses P = ' + str(threshold))
    plt.savefig('tuning_graph_images/' + name + '_threshold_selectivity/' + name + '_threshold_experiment_error_bar_plot.png', transparent=True)
   
    #plt.savefig('tuning_graph_images/experiment' + str(exp_number) + '/neuron' + str(cur_neuron) + '_tuning_graph.png', transparent=True)
    plt.show


#plt.hist(x, bins=None, range=None,histtype='bar', align='mid', orientation='vertical')



def get_all_sup_sensitive_neurons(cre):
       
        
    name = cre[:3]
    og_arr = np.empty(5, int)
    TF_SbC_tuning = np.array(og_arr).T   
    cell_exp = boc.get_ophys_experiments(cre_lines=[cre], stimuli=['drifting_gratings'])
    
    for i_exp in cell_exp:

        data_set = boc.get_ophys_experiment_data(i_exp['id'])
        dg = DriftingGratings(data_set)

        dg_tbl = data_set.get_stimulus_table("drifting_gratings")
        dg_columns = list(dg_tbl.columns[0:2])
        dg_mean_sweep_events = dg.mean_sweep_response.iloc[:,:-1]
        total_neurons = dg_mean_sweep_events.shape[1]
        threshold = 0.05
        shuffles = 10000
        all_cell_responses =  np.zeros(total_neurons)

        for cur_neuron in range(total_neurons):
            #Get Response Matrix
            cur_condition_sig = get_null_matrix(dg_tbl, cur_neuron, dg_mean_sweep_events, shuffles)
            response_matrix = get_response_matrix(dg_tbl, cur_neuron, dg_mean_sweep_events, threshold, cur_condition_sig)#suppressed       
            all_cell_responses[cur_neuron] = np.sum(response_matrix)

        TF_SbC_tuning = np.append(TF_SbC_tuning, all_cell_responses)
        
    fig, ax  = plt.subplots()
    
    
    ax.hist(TF_SbC_tuning, bins = 41, range=(0,41))
    ax.set_xlabel('Number of Suppressed Conditions')
    ax.set_ylabel('Number of Cells')

    ax.set_title(name + ' Histogram of Suppressed Responses P = ' + str(threshold))
    plt.savefig('tuning_graph_images/' + name + '_distributions/' + name + '_suppression_histogram.png', transparent=True)

    return TF_SbC_tuning

#plt.hist(x, bins=None, range=None,histtype='bar', align='mid', orientation='vertical')



def get_all_exc_sensitive_neurons(cre):
       
        
    name = cre[:3]
    og_arr  = np.empty(5, int)
    TF_SbC_tuning = np.array(og_arr).T   
    cell_exp = boc.get_ophys_experiments(cre_lines=[cre], stimuli=['drifting_gratings'])
    
    for i_exp in cell_exp:

        data_set = boc.get_ophys_experiment_data(i_exp['id'])
        dg = DriftingGratings(data_set)

        dg_tbl = data_set.get_stimulus_table("drifting_gratings")
        dg_columns = list(dg_tbl.columns[0:2])
        dg_mean_sweep_events = dg.mean_sweep_response.iloc[:,:-1]
        total_neurons = dg_mean_sweep_events.shape[1]
        threshold = 0.05
        shuffles = 10000
        all_cell_responses =  np.zeros(total_neurons)

        for cur_neuron in range(total_neurons):
            #Get Response Matrix
            cur_condition_sig = get_null_matrix(dg_tbl, cur_neuron, dg_mean_sweep_events, shuffles)

            response_matrix = get_response_matrix2(dg_tbl, cur_neuron, dg_mean_sweep_events, threshold, cur_condition_sig)#excited
            
            all_cell_responses[cur_neuron] = np.sum(response_matrix)

        TF_SbC_tuning = np.append(TF_SbC_tuning, all_cell_responses)
        
    fig, ax  = plt.subplots()
    
    ax.hist(TF_SbC_tuning, bins = 41, range=(0,41))
    ax.set_xlabel('Number of Excited Conditions')
    ax.set_ylabel('Number of Cells')

    ax.set_title(name + ' Histogram of Excited Responses P = ' + str(threshold))
    plt.savefig('tuning_graph_images/' + name + '_distributions/' + name + '_excitation_histogram.png', transparent=True)

    return TF_SbC_tuning

#plt.hist(x, bins=None, range=None,histtype='bar', align='mid', orientation='vertical')



def get_all_cell_ids(cre):
       
        
    name = cre[:3]
    og_arr  = np.empty(5, int)
    TF_SbC_cell_ids = np.array(og_arr).T   
    cell_exp = boc.get_ophys_experiments(cre_lines=[cre], stimuli=['drifting_gratings'])
    
    for i_exp in cell_exp:

        data_set = boc.get_ophys_experiment_data(i_exp['id'])
        dg = DriftingGratings(data_set)

        dg_tbl = data_set.get_stimulus_table("drifting_gratings")
        dg_columns = list(dg_tbl.columns[0:2])
        dg_mean_sweep_events = dg.mean_sweep_response.iloc[:,:-1]
        total_neurons = dg_mean_sweep_events.shape[1]
        threshold = 0.05
        shuffles = 10000
        all_cell_responses =  np.zeros(total_neurons)
        TF_SbC_cell_ids = np.append(TF_SbC_cell_ids, dg.cell_id)

        
    
    return TF_SbC_cell_ids

def sup_exc_heat_map(mat,cre,thresh):
       
    name = cre[:3]
    
    fig, ax  = plt.subplots()
    
    
    
    im = ax.imshow(mat, cmap='Reds', interpolation='nearest')
    ax.set_xlabel('suppressed conditions')
    ax.set_ylabel('excited conditions')
    plt.gca().invert_yaxis()
    
    fig.subplots_adjust(right=0.9)
    cbar_ax = fig.add_axes([0.95, 0.05, 0.05, 0.85])
    cbar = fig.colorbar(im, cax=cbar_ax)



    

    ax.set_title(name + ' Heatmap of Suppressed and Excited Conditions = ' + str(thresh))
    plt.savefig('tuning_graph_images/' + name + '_distributions/' + name + '_distribution_heat_map.png', transparent=True)


cells = boc.get_cell_specimens()
cells = pd.DataFrame.from_records(cells)

vip_cre = 'VIP-IRES-Cre'
sst_cre = 'Sst-IRES-Cre'
cux2_cre = 'Cux2-CreERT2'
nr5_cre =  'Nr5a1-Cre'
slc_cre = 'Slc17a7-IRES2-Cre'

visp_struct = 'VISp'

#nr5a1, receptive field area, natrual movie reliability for 3 natural movies, image selectivity,

# what is response of blank based on tf before it, 
# tf with more suppression might have steeper response during blank if it precedes spontaneous activity

def get_metrics_df(cells, cre):
    
    e_sup = get_all_sup_sensitive_neurons(cre)
    e_exc = get_all_exc_sensitive_neurons(cre)
    ids = get_all_cell_ids(cre)


    data = {'cell_specimen_id':ids,'Supressed Conditions':e_sup, 'Excited Conditions':e_exc}
    
    df = pd.DataFrame(data, columns = ['cell_specimen_id', 'Supressed Conditions', 'Excited Conditions'])
    
    wanted = boc.get_experiment_containers(cre_lines=[cre])
    wanted_ids = [ ec['id'] for ec in wanted]
    wanted_cells = cells[cells['experiment_container_id'].isin(wanted_ids)]
    
    df_cd = pd.merge(df, wanted_cells, how='inner', on = 'cell_specimen_id')
    
    return df_cd




def get_quads(cre):
    
    e_sup = get_all_sup_sensitive_neurons(cre)
    e_exc = get_all_exc_sensitive_neurons(cre)
    
    num_neurons = len(e_sup)
    feature_matrix = np.zeros((41,41))
    

    for i_neuron in range(num_neurons):
        x = int(e_sup[i_neuron])
        y = int(e_exc[i_neuron])
        feature_matrix[y,x] += 1
    
    pre_res = np.where(feature_matrix == 0, -1, feature_matrix)
    res = np.where(pre_res>0, np.log(pre_res), pre_res) 

   
    heat_map = sup_exc_heat_map(res, cre, 0.05)

get_quads(nsst_cre)

 get_quads(vip_cre)

 get_quads(nr5_cre)

 get_quads(cux2_cre)

 get_quads(slc_cre)

def determine_features(sup,exc):
    
    title = "null"
    
    if (sup > 10) & (exc == 0):
        title = "suppressed"
    
    if (sup < 10) & (exc == 0):
        title = "unresponsive"
        
    elif (sup < 10) & (0 < exc < 10):
        title = "narrow-tuned"
        
    elif (sup < 10) & (exc > 10):
        title = "broad-tuned"
        
    elif (sup > 10) & (0 < exc < 10):
        title = "narrow-tuned w/ suppression"
    
    elif (sup > 10) & (exc > 10):
        title = "broad-tuned w/ suppression"
        
    return title
    
    

def get_activites(condition_tbl):
    
    condition_len = len(condition_tbl)
    
    activity_arr  = np.empty(condition_len, dtype=np.dtype('U27'))

    for i in range(condition_len):
        activity_arr[i] = determine_features(condition_tbl.iloc[i][0],condition_tbl.iloc[i][1])

    return activity_arr

def activity_histogram(cre,metric_tbl):
    metric_conditions = metric_tbl.iloc[:,1:3]
    metric_activities = get_activites(metric_conditions)
    
    fig, ax  = plt.subplots()

    
    n_bins = len(np.unique(metric_activities))
    n, bins, patches = plt.hist(metric_activities, bins=n_bins, edgecolor='black')
    ticks = [(patch._x0 + patch._x1)/2 for patch in patches]
    plt.xticks(rotation=90)
    plt.xticks(ticks)
    
    
    name = cre.split('-')[0]
    ax.set_title(name + ' Activity Histogram')
    plt.savefig('distribution_plots/' + name + '_distributions/' + name + '_activity_histogram.png', transparent=False)
    plt.show()


def add_metric_activity(metric_tbl):
    metric_conditions = metric_tbl.iloc[:,1:3]
    metric_activities = get_activites(metric_conditions)
    metric_tbl.insert(3, "Activity Type", metric_activities, False)

activity_histogram(vip_cre,vip_metrics)

activity_histogram(sst_cre,sst_metrics)

activity_histogram(cux2_cre,cux2_metrics)

activity_histogram(nr5_cre,nr5_metrics)

activity_histogram(slc_cre,slc_metrics)



def metric_histogram(metric, metric_tbl, x_axis_title, title):
    
    suppressed_metric = metric_tbl.loc[metric_tbl['Activity Type'] == 'suppressed', metric].values

    unresponsive_metric = metric_tbl.loc[metric_tbl['Activity Type'] == 'unresponsive',  metric].values
    
    narrow_tuned_metric = metric_tbl.loc[metric_tbl['Activity Type'] == 'narrow-tuned',  metric].values
    
    broad_tuned_metric = metric_tbl.loc[metric_tbl['Activity Type'] == 'broad-tuned',  metric].values
    
    sup_narrow_tuned_metric = metric_tbl.loc[metric_tbl['Activity Type'] == 'narrow-tuned w/ suppression',  metric].values
    

#     sup_broad_tuned_metric = metric_tbl.loc[metric_tbl['Activity Type'] == 'broad-tuned w/ suppression',  metric].values
#     sup_broad_tuned_metric_activities = np.around(sup_broad_tuned_metric, decimals=5)
#     sup_broad_tuned_bins = len(np.unique(sup_broad_tuned_metric_activities))



    # n, bins, patches = plt.hist(suppressed_metric_activities, bins=suppressed_bins, edgecolor='black')
    # ticks = [(patch._x0 + patch._x1)/2 for patch in patches]
    # #plt.xticks(rotation=90)
    #plt.xticks(ticks)

    bin_size = 50
    fig, (ax1, ax2, ax3, ax4, ax5) = plt.subplots(5, 1, figsize=(10, 15))
    fig.suptitle(title)

    ax1.hist(suppressed_metric, bin_size, edgecolor='black')
    ax1.set_ylabel('Suppressed')

    ax2.hist(unresponsive_metric,bin_size, edgecolor='black')
    ax2.set_ylabel('Unresponsive')

    ax3.hist(narrow_tuned_metric,bin_size, edgecolor='black')
    ax3.set_ylabel('Narrow-tuned')

    ax4.hist(broad_tuned_metric, bins=bin_size, edgecolor='black')
    ax4.set_ylabel('Broad-tuned')

    ax5.hist(sup_narrow_tuned_metric, bins=bin_size, edgecolor='black')
    ax5.set_ylabel('narrow-tuned w/ suppression')

#     ax6.hist(sup_broad_tuned_metric_activities, bins=sup_broad_tuned_bins, edgecolor='black')
#     ax6.set_ylabel('Broad-tuned w/ suppression')
    ax5.set_xlabel(x_axis_title)
    

    plt.savefig(title +'.png', transparent=False)

    plt.show()



metric_histogram('rf_area_off_lsn', vip_metrics, 'Area', "Off Receptive Field Across Activity Types in VIP")

metric_histogram('rf_area_on_lsn', vip_metrics, 'Area', "On Receptive Field Across Activity Types in VIP")

metric_histogram('rf_area_off_lsn', sst_metrics, 'Area', "Off Receptive Field Across Activity Types in SST")

metric_histogram('rf_area_on_lsn', sst_metrics, 'Area', "On Receptive Field Across Activity Types in SST")
